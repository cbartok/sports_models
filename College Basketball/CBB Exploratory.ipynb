{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn import linear_model, svm, tree, ensemble\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pull in data and seperate the features and labels\n",
    "full_data = pd.read_csv('historical_cbb_data.csv')\n",
    "full_data['neutral'] = np.where(full_data['neutral'] == 1, 1, 0)\n",
    "train = full_data[full_data['year'] != 2019]\n",
    "test = full_data[full_data['year'] == 2019]\n",
    "train_labels = np.array(train['result'])\n",
    "test_labels = np.array(test['result'])\n",
    "train_odds = np.array(train['close'])\n",
    "test_odds = np.array(test['close'])\n",
    "\n",
    "train = train.drop(['result', 'year', 'close'], axis=1)\n",
    "test = test.drop(['result', 'year', 'close'], axis=1)\n",
    "\n",
    "feature_list = list(train.columns)\n",
    "train_features = np.array(train)\n",
    "test_features = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_loss_function(y_true, y_pred):\n",
    "    diff = np.abs(y_true - y_pred)\n",
    "    ##If the difference is greater than 2 scores, set it to 16\n",
    "    diff = np.where(diff > 15, 15, diff)\n",
    "    return np.mean(diff)\n",
    "\n",
    "score = make_scorer(truncated_loss_function, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-854537b5e52f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##Closing vegas lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_odds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\cameron\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \"\"\"\n\u001b[0;32m    171\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 172\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\cameron\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\cameron\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\cameron\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "##Closing vegas lines\n",
    "mean_absolute_error(test_odds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.172240249080273"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Baseline only using average\n",
    "mean_absolute_error(np.repeat(np.array([np.mean(train_labels)]), len(test_labels)), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49112559691786806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.204796029965557"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Baseline linear regression with only neutral and f+\n",
    "subset_data = full_data[['neutral', 'team_rankings_rating', 'year', 'result']]\n",
    "base_train = subset_data[subset_data['year'] != 2019]\n",
    "base_test = subset_data[subset_data['year'] == 2019]\n",
    "base_train_labels = np.array(base_train['result'])\n",
    "base_test_labels = np.array(base_test['result'])\n",
    "\n",
    "base_train = base_train.drop(['result', 'year'], axis=1)\n",
    "base_test = base_test.drop(['result', 'year'], axis=1)\n",
    "\n",
    "subset_feature_list = list(base_train.columns)\n",
    "base_train_features = np.array(base_train)\n",
    "base_test_features = np.array(base_test)\n",
    "\n",
    "base_linear_regr = linear_model.LinearRegression().fit(base_train_features, base_train_labels)\n",
    "base_ols_coefficients = pd.concat([pd.DataFrame(subset_feature_list),pd.DataFrame(np.transpose(base_linear_regr.coef_))], axis = 1)\n",
    "print(base_linear_regr.score(base_train_features, base_train_labels))\n",
    "mean_absolute_error(base_linear_regr.predict(base_test_features), base_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4943427029062513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.180812849521653"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Linear Regression\n",
    "linear_regr = linear_model.LinearRegression().fit(train_features, train_labels)\n",
    "ols_coefficients = pd.concat([pd.DataFrame(feature_list),pd.DataFrame(np.transpose(linear_regr.coef_))], axis=1)\n",
    "print(linear_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(linear_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n",
      "-7.300720090766176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.182770885243073"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Lasso Regression\n",
    "lasso_model = linear_model.Lasso()\n",
    "parameters = {'alpha':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 10]}\n",
    "lasso_regr = GridSearchCV(lasso_model, parameters, cv=5, scoring=score).fit(train_features, train_labels)\n",
    "print(lasso_regr.best_params_)\n",
    "print(lasso_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(lasso_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4933435464108724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.182770885243073"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Fit best Lasso using parameter calculated above\n",
    "lasso_model = linear_model.Lasso(alpha=0.1)\n",
    "lasso_regr = lasso_model.fit(train_features, train_labels)\n",
    "print(lasso_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(lasso_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4781316113595314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.223154760184627"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Ridge Regression\n",
    "ridge_regr = linear_model.RidgeCV(cv=5).fit(train_features, train_labels)\n",
    "ridge_coefficients = pd.concat([pd.DataFrame(feature_list),pd.DataFrame(np.transpose(ridge_regr.coef_))], axis=1)\n",
    "print(ridge_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(ridge_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47796207772411303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.22322378916986"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Elastic Net\n",
    "en_regr = linear_model.ElasticNetCV(cv=5, random_state=0).fit(train_features, train_labels)\n",
    "en_coefficients = pd.concat([pd.DataFrame(feature_list),pd.DataFrame(np.transpose(en_regr.coef_))], axis=1)\n",
    "print(en_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(en_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVR using default values\n",
    "svr_regr = svm.SVR(gamma='scale').fit(train_features, train_labels)\n",
    "print(svr_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(svr_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'epsilon': 1, 'C': 0.1}\n",
      "-7.28635848694344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.17723495637139"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##SVR with grid search\n",
    "parameters = {'C': [0.1, 1, 2, 5, 10, 15, 25, 50, 100], 'epsilon': [0, 0.5, 1, 2, 3, 4, 5, 8, 10, 20], 'kernel': ['linear', 'rbf', 'poly']}\n",
    "svr = svm.SVR(gamma='scale')\n",
    "svr_regr = RandomizedSearchCV(svr, parameters, cv=5, n_iter=100, scoring=score).fit(train_features, train_labels)\n",
    "print(svr_regr.best_params_)\n",
    "print(svr_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(svr_regr.predict(test_features), test_labels)\n",
    "##Optimal hyper parameters\n",
    "#C:0.1, epsilon: 1 , kernel:linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4933209462579541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.17723495637139"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##SVR with the optimal hyperparameters from above\n",
    "svr_model = svm.SVR(gamma='scale', C=0.1, epsilon=1, kernel='linear')\n",
    "svr_regr = svr_model.fit(train_features, train_labels)\n",
    "print(svr_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(svr_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Decision Tree No pruning\n",
    "decision_tree_regr = tree.DecisionTreeRegressor(criterion='mae', random_state=0).fit(train_features, train_labels)\n",
    "print(decision_tree_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(decision_tree_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Decision Tree CV\n",
    "parameters = {'max_depth':list(range(1,33)), 'min_samples_split': [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.90, 0.95, 0.99], 'min_samples_leaf':([0.001, 0.005, .01, .05] + list(np.linspace(.1, .5, 9)))}\n",
    "decision_tree = tree.DecisionTreeRegressor(criterion='mae', random_state=0)\n",
    "decision_tree_regr = RandomizedSearchCV(decision_tree, parameters, cv=5, scoring=score, n_iter=100).fit(train_features, train_labels)\n",
    "print(decision_tree_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(decision_tree_regr.predict(test_features), test_labels)\n",
    "##Optimal hyper parameters\n",
    "##Full Model: max_depth 5, min_samples_leaf = .01, min_samples_split=.001, random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Decision tree with optimal hyper parameters\n",
    "decision_tree_regr = tree.DecisionTreeRegressor(criterion='mae', random_state=0, max_depth=5, min_samples_leaf=.01, min_samples_split=.001).fit(train_features, train_labels)\n",
    "print(decision_tree_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(decision_tree_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adaboost tree using the optimal parameters from above\n",
    "##Don't use adaboost because very sensitive to outliers\n",
    "##max_depth 4, min_samples_leaf = .1, min_samples_split=.1, random_state=0\n",
    "decision_tree = tree.DecisionTreeRegressor(criterion='mae', random_state=0, max_depth=4, min_samples_leaf=.1, min_samples_split=.1)\n",
    "parameters ={'learning_rate': list(np.linspace(.1, 1, 10)), 'n_estimators': list(range(10, 110, 10))}\n",
    "adaboost_tree = ensemble.AdaBoostRegressor(base_estimator=decision_tree, random_state=0)\n",
    "adaboost_tree_regr = GridSearchCV(adaboost_tree, parameters, cv=5, scoring=score).fit(train_features, train_labels)\n",
    "print(adaboost_tree_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(adaboost_tree_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cbartok\\AppData\\Local\\Continuum\\miniconda3\\envs\\cameron\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'min_samples_split': 0.01, 'min_samples_leaf': 0.001, 'max_depth': 18}\n",
      "-6.9954166477246895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.206103896103896"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Random Forest CV\n",
    "parameters = {'max_depth':list(range(1,20)), 'min_samples_split': [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.90, 0.95, 0.99],\\\n",
    "              'min_samples_leaf':([0.001, 0.005, .01, .05] + list(np.linspace(.1, .25, .5, .9))), 'n_estimators': [10, 20, 50, 75, 100, 150, 200]}\n",
    "random_forest = ensemble.RandomForestRegressor(criterion='mae', random_state=0, max_features=1/3)\n",
    "random_forest_regr = RandomizedSearchCV(random_forest, parameters, cv=5, n_iter=100, scoring=score).fit(train_features, train_labels)\n",
    "print(random_forest_regr.best_params_)\n",
    "print(random_forest_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(random_forest_regr.predict(test_features), test_labels)\n",
    "##Best parameters max depth 18, min_sample_leafs .001, min_samples_split .01, n_estimators 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5184256918204613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.206103896103896"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Fit random forest with best parameters from above\n",
    "random_forest_model = ensemble.RandomForestRegressor(criterion='mae', random_state=0, max_features=1/3, max_depth=18, min_samples_leaf=.001, min_samples_split=.01, n_estimators=50)\n",
    "random_forest_regr = random_forest_model.fit(train_features, train_labels)\n",
    "print(random_forest_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(random_forest_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_lambda': 8.0, 'reg_alpha': 6.0, 'max_depth': 18, 'learning_rate': 0.05, 'gamma': 0.8, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.01, 'booster': 'gbtree'}\n",
      "-6.733532278041718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.232774008253608"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##xgboost CV\n",
    "dtrain = xgb.DMatrix(train_features, label=train_labels)\n",
    "dtest = xgb.DMatrix(test_features, label=test_labels)\n",
    "parameters = {'max_depth':list(range(1,20)),  'learning_rate':[0.01, .02, .05]+list(np.linspace(.1, 1, 10)), 'colsample_bytree':[0.01, .02, .05]+list(np.linspace(.1, 1, 10)), 'colsample_bylevel':[0.01, .02, .05]+list(np.linspace(.1, 1, 10)), 'reg_alpha':[0.01, .1, .5] + list(np.linspace(1,10,10)), 'reg_lambda':[0.01, .1, .5] + list(np.linspace(1,10,10)), 'booster':['gbtree', 'gblinear'], 'gamma':[0.01, .02, .05]+list(np.linspace(.1, 1, 10))}\n",
    "xgboost_model = xgb.XGBRegressor(eval_metric='mae', seed=0, objective='reg:squarederror')\n",
    "xgboost_regr = RandomizedSearchCV(xgboost_model, parameters, cv=5, n_iter=100, scoring=score).fit(train_features, train_labels)\n",
    "print(xgboost_regr.best_params_)\n",
    "print(xgboost_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(xgboost_regr.predict(test_features), test_labels)\n",
    "#xgboost best params colsample_bylevel .01, colsample_bytree .9, learning_rate=.05, max_depth 18, reg_alpha 6.0, reg lambda 8.0, gamma 0.8, booster gbtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5783228122126856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.232774008253608"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##xgboost with best parameters above \n",
    "dtrain = xgb.DMatrix(train_features, label=train_labels)\n",
    "dtest = xgb.DMatrix(test_features, label=test_labels)\n",
    "xgboost_model = xgb.XGBRegressor(eval_metric='mae', seed=0, objective='reg:squarederror', colsample_bylevel=.01, colsample_bytree=.9, learning_rate=.05, max_depth=18, reg_alpha=6, reg_lambda=8, gamma=0.8, booster='gbtree')\n",
    "xgboost_regr = xgboost_model.fit(train_features, train_labels)\n",
    "print(xgboost_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(xgboost_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': [1, 1, 1.5, 1]}\n",
      "-7.057076103165457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.177787686675773"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##ensemble method using xgboost, svr, random forest, and lasso regression models with cross validation for weights\n",
    "ensemble_model = ensemble.VotingRegressor([('xgb', xgboost_model), ('svr', svr_model), ('rf', random_forest_model), ('lasso', lasso_model)])\n",
    "parameters = {'weights': [[1,1,1,1], [1.5, 1, 1, 1], [1,1.5,1,1], [1,1,1.5,1], [1,1,1,1.5], [1.5,1.5,1,1], [1.5,1,1.5,1], [1.5,1,1,1.5], [1,1.5,1.5,1],[1,1.5,1,1.5], [1,1,1.5,1.5]]}\n",
    "ensemble_regr = GridSearchCV(ensemble_model, parameters, cv=5, scoring=score).fit(train_features, train_labels)\n",
    "print(ensemble_regr.best_params_)\n",
    "print(ensemble_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(ensemble_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5238904179771711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.177787686675773"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##ensemble method using xgboost, svr, random forest, and lasso regression models\n",
    "ensemble_model = ensemble.VotingRegressor([('xgb', xgboost_model), ('svr', svr_model), ('rf', random_forest_model), ('lasso', lasso_model)], weights=[1,1,1.5,1])\n",
    "ensemble_regr = ensemble_model.fit(train_features, train_labels)\n",
    "print(ensemble_regr.score(train_features, train_labels))\n",
    "mean_absolute_error(ensemble_regr.predict(test_features), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'odds':test_odds, 'prediction':ensemble_regr.predict(test_features), 'result':test_labels})\n",
    "results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': [1.5, 1, 1, 1]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_regr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cbb_full_model.pickle', 'wb') as cbb_file:\n",
    "    pickle.dump(ensemble_model, cbb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cbb_model.pickle', 'wb') as cbb_file:\n",
    "    pickle.dump(ensemble_model, cbb_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
